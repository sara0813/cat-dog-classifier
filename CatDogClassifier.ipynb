{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Í∏∞Î≥∏ÏÑ§Ï†ï**"
      ],
      "metadata": {
        "id": "jlnQ4iz2wwRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi || true\n",
        "!python -V\n",
        "!pip -q install kaggle --upgrade\n",
        "\n",
        "import os, random, time, shutil, zipfile, gc\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "# GPU ÌôïÏù∏\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ÏãúÎìú Í≥†Ï†ï\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(SEED)\n"
      ],
      "metadata": {
        "id": "8AYcnzaKyJM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú**"
      ],
      "metadata": {
        "id": "9Cql4Ay5yRsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"üëâ kaggle.jsonÏùÑ ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî (Kaggle > Account > Create New API Token)\")\n",
        "uploaded = files.upload()  # kaggle.json ÏóÖÎ°úÎìú\n",
        "\n",
        "os.makedirs(Path.home()/\".kaggle\", exist_ok=True)\n",
        "shutil.move(\"kaggle.json\", str(Path.home()/\".kaggle/kaggle.json\"))\n",
        "os.chmod(str(Path.home()/\".kaggle/kaggle.json\"), 0o600)\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú\n",
        "!kaggle competitions download -c dogs-vs-cats -f train.zip -p /content\n",
        "!ls -lh /content/train.zip\n"
      ],
      "metadata": {
        "id": "AhdL_dCUxmlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = Path(\"/content/dogs_v_cats\")\n",
        "RAW_DIR = DATA_ROOT / \"raw_train\"\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ÏïïÏ∂ï Ìï¥Ï†ú (Ïù¥ÎØ∏ ÌíÄÎ†§ÏûàÏúºÎ©¥ Îã§Ïãú Ïïà ÌíÄÏñ¥ÎèÑ Îê®)\n",
        "if not any(RAW_DIR.iterdir()):\n",
        "    t0 = time.time()\n",
        "    with zipfile.ZipFile(\"/content/train.zip\") as z:\n",
        "        z.extractall(RAW_DIR)\n",
        "    print(\"ÏïïÏ∂ï Ìï¥Ï†ú ÏôÑÎ£å:\", round(time.time()-t0, 2), \"Ï¥à\")\n",
        "\n",
        "# ÌïòÏúÑ Ìè¥ÎçîÍπåÏßÄ Îã§ Îí§Ï†∏ÏÑú Ïù¥ÎØ∏ÏßÄ Ï∞æÍ∏∞\n",
        "all_imgs = sorted([p for p in RAW_DIR.rglob(\"*\") if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]])\n",
        "\n",
        "print(\"Ï¥ù Ïù¥ÎØ∏ÏßÄ:\", len(all_imgs))\n",
        "if len(all_imgs) > 0:\n",
        "    print(\"ÏòàÏãú:\", all_imgs[0].name, \"‚Ä¶\", all_imgs[-1].name)\n",
        "else:\n",
        "    raise RuntimeError(\"‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄÍ∞Ä Î∞úÍ≤¨ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Í≤ΩÎ°ú ÌôïÏù∏ ÌïÑÏöî!\")\n"
      ],
      "metadata": {
        "id": "D9_SrhqOyWtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DogsCatsDataset(Dataset):\n",
        "    def __init__(self, files, transform=None):\n",
        "        self.files = files\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def _label_from_name(self, path: Path):\n",
        "        name = path.name.lower()\n",
        "        if name.startswith(\"cat\"):\n",
        "            return 0\n",
        "        elif name.startswith(\"dog\"):\n",
        "            return 1\n",
        "        if \"cat\" in name: return 0\n",
        "        if \"dog\" in name: return 1\n",
        "        raise ValueError(f\"ÎùºÎ≤® Ïïå Ïàò ÏóÜÏùå: {path.name}\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.files[idx]\n",
        "        label = self._label_from_name(path)\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "o4yYSRlMyo7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8:2 Î∂ÑÌï†\n",
        "random.shuffle(all_imgs)\n",
        "split_idx = int(len(all_imgs) * 0.8)\n",
        "train_files = all_imgs[:split_idx]\n",
        "valid_files = all_imgs[split_idx:]\n",
        "\n",
        "print(f\"Train: {len(train_files)}, Valid: {len(valid_files)}\")\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "valid_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "train_ds = DogsCatsDataset(train_files, transform=train_tfms)\n",
        "valid_ds = DogsCatsDataset(valid_files, transform=valid_tfms)\n",
        "\n",
        "pin_memory = (device.type == \"cuda\")\n",
        "num_workers = min(4, os.cpu_count() or 1)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=128, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n"
      ],
      "metadata": {
        "id": "i7d5I6MOzpeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "weights = ResNet18_Weights.DEFAULT\n",
        "model = resnet18(weights=weights)\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
        "\n",
        "use_amp = (device.type == \"cuda\")\n",
        "if use_amp:\n",
        "    scaler = torch.amp.GradScaler(device=\"cuda\")\n",
        "else:\n",
        "    scaler = torch.amp.GradScaler(enabled=False)\n",
        "\n",
        "print(\"AMP ÏÇ¨Ïö©:\", use_amp)\n"
      ],
      "metadata": {
        "id": "9BT82VYfzqzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, targets):\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    return (preds == targets).float().mean().item()\n",
        "\n",
        "EPOCHS = 5\n",
        "best_acc = -1.0\n",
        "save_path = \"/content/resnet18_dogs_cats_best.pt\"\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0.0, 0.0\n",
        "\n",
        "    pbar = tqdm(total=len(train_loader), desc=f\"[Epoch {epoch}/{EPOCHS}] Train\", unit=\"batch\")\n",
        "    for i, (imgs, labels) in enumerate(train_loader, start=1):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        if use_amp:\n",
        "            with torch.amp.autocast(\"cuda\"):\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_acc  += accuracy(outputs, labels)\n",
        "        pbar.set_postfix(loss=f\"{train_loss/i:.4f}\", acc=f\"{(train_acc/i)*100:.2f}%\")\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, val_acc = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        pbar_v = tqdm(total=len(valid_loader), desc=f\"[Epoch {epoch}/{EPOCHS}] Valid\", unit=\"batch\")\n",
        "        for j, (imgs, labels) in enumerate(valid_loader, start=1):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            if use_amp:\n",
        "                with torch.amp.autocast(\"cuda\"):\n",
        "                    outputs = model(imgs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "            else:\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_acc  += accuracy(outputs, labels)\n",
        "            pbar_v.set_postfix(loss=f\"{val_loss/j:.4f}\", acc=f\"{(val_acc/j)*100:.2f}%\")\n",
        "            pbar_v.update(1)\n",
        "        pbar_v.close()\n",
        "\n",
        "    print(f\"Epoch {epoch}: Train acc={train_acc/len(train_loader)*100:.2f}%, Val acc={val_acc/len(valid_loader)*100:.2f}%\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if val_acc/len(valid_loader) > best_acc:\n",
        "        best_acc = val_acc/len(valid_loader)\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"‚úÖ Best model saved (val_acc={best_acc*100:.2f}%)\")"
      ],
      "metadata": {
        "id": "XXzefJKazst_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Î™®Îç∏ Î°úÎìú\n",
        "model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "label2name = {0: \"cat\", 1: \"dog\"}\n",
        "idxs = np.random.choice(len(valid_ds), size=5, replace=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx in idxs:\n",
        "        img_path = valid_files[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        inp = valid_tfms(img).unsqueeze(0).to(device)\n",
        "        with torch.amp.autocast(\"cuda\") if use_amp else torch.no_grad():\n",
        "            out = model(inp)\n",
        "        pred = out.argmax(dim=1).item()\n",
        "        print(f\"[ÏòàÏ∏°: {label2name[pred]}] ‚Üí {img_path.name}\")\n",
        "        display(img.resize((256,256)))\n"
      ],
      "metadata": {
        "id": "QTXChEuF3Rz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÏµúÏ¢Ö Validation Ï†ïÌôïÎèÑ Ìïú Î≤à Îçî Í≥ÑÏÇ∞\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in valid_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "val_acc = correct / total * 100\n",
        "print(f\"ÏµúÏ¢Ö Validation Accuracy: {val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "yLJ2Beyl3wvC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}